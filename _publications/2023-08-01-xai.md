---
title: "Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images"
collection: publications
permalink: /publication/2023-08-01-xai
excerpt: 'Deep learning shows promise for medical image analysis but lacks interpretability, hindering adoption in healthcare. Attribution techniques that explain model reasoning may increase trust in deep learning among clinical stakeholders. This paper aimed to evaluate attribution methods for illuminating how deep neural networks analyze medical images. Using adaptive path-based gradient integration, we attributed predictions from brain tumor MRI and COVID-19 chest X-ray datasets made by recent deep convolutional neural network models. The technique highlighted possible biomarkers, exposed model biases, and offered insights into the links between input and prediction. Our analysis demonstrates the method's ability to elucidate model reasoning on these datasets. The resulting attributions show promise for improving deep learning transparency for domain experts by revealing the rationale behind predictions. This study advances model interpretability to increase trust in deep learning among healthcare stakeholders.'
date: 2023-08-01
venue: '<i>arXiv preprint arXiv:2208.00953</i>'
paperurl: 'https://arxiv.org/abs/2208.00953'
citation: 'Brima, Yusuf, and Marcellin Atemkeng. "Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images" arXiv preprint arXiv:2208.00953 (2023).'
---

[Download paper here](https://arxiv.org/abs/2208.00953)

Recommended citation: Brima, Yusuf, and Marcellin Atemkeng. "Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images" arXiv preprint arXiv:2208.00953 (2023).