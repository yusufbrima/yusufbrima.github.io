---
permalink: /
title: "About me"
excerpt: " "
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

* My research interests include Representation Learning, Causality, Explainability, Interpretability, Computational Entrepreneurship, Mathematical Modelling particularly in building end-to-end systems with high socio-technical impacts in healthcare. [[Curriculum Vitae](http://yusufbrima.github.io/files/Academic_CV_Yusuf_Brima.pdf)]
* Ph.D. in [Cognitive Science (expected May 2025)](https://www.comco.uni-osnabrueck.de/projekte/yusuf_brima.html) at [Osnabrück University](https://www.comco.uni-osnabrueck.de/), advised by [Prof. Gunther Heidemann](https://www.ikw.uni-osnabrueck.de/en/research_groups/computer_vision/people/heidemann_gunther.html) and [Prof. Simone Pika](http://www.ikw.uni-osnabrueck.de/en/research_groups/comparative_biocognition.html).
* MSc. in [Mathematical Sciences](https://cs.du.ac.bd/) at [The African Institute of Mathematical Sciences (AIMS) ](https://www.aims.ac.rw/), advised by [Dr. Marcellin Atemkeng](https://www.ru.ac.za/mathematics/people/staff/marcelatemkeng/#d.en.232420).
* MSc. student in the [Computer Science and Engineering Department](https://cs.du.ac.bd/) at [University of Dhaka](https://www.du.ac.bd/body/CSE), advised by [Prof. Mosaddek Hossain Kamal](https://www.du.ac.bd/body/faculty_details/CSE/1764).
* BSc. in Computer Science from the [University of Makeni](http://www.unimak.edu.sl/).

<hr />

<figure id="Original_vs_Reconstructed">
  <img src="http://yusufbrima.github.io/images/Original_vs_Reconstructed.gif" style="width:90%;" alt="Time-domain, frequency-domain and time-frequency representations of a sine waveform across different frequencies sampled at 16KHz for 1 seconds.">
  <figcaption>Time-domain, frequency-domain and time-frequency representations of a sine waveform across different frequencies sampled at 16KHz for 1 seconds. The top row is the original signal and the bottom row is the reconstructed version for the disentangled Variational Auto Encoder.</figcaption>
</figure>

<hr />

<figure id="sawtooth">
  <img src="http://yusufbrima.github.io/images/sawtooth.gif" style="width:90%;" alt="Time-domain, time-frequency and frequency-domain representations of a sawtooth waveform across different frequencies sampled at 16KHz for 2 seconds.">
  <figcaption>Time-domain, time-frequency and frequency-domain representations of a sawtooth waveform across different frequencies sampled at 16KHz for 2 seconds each.</figcaption>
</figure>

<hr />

<figure id="contrastive_representation_learning">
  <img src="http://yusufbrima.github.io/images/mnist_tripplet_animation_advanced.gif" style="width:90%;" alt="Triplet-based contrastive representation learning of MNIST validation set.">
  <!-- <img src="http://yusufbrima.github.io/images/mnist_scl_animation.gif" style="width:45%;"  alt="Supervised Contrastive Learned-based evaluation of MNIST validation set."> -->
  <figcaption>Visualizing the convergce of clusters of classes in the MNIST validation set using both Triplet (Left) and Supervised Contrastive Representation Learning</figcaption>
</figure>

<hr />

<figure id="decorrelated_audio_representations">
  <img src="http://yusufbrima.github.io/images/bt_small_train_modified_BN.gif" style="width:45%;" alt="128-dimensional latent representation of modified Barlow Twins.">
  <img src="http://yusufbrima.github.io/images/bt_small_train_original.gif" style="width:45%;"  alt="128-dimensional latent representation of modified Barlow Twins.">
  <figcaption>Visualizing the convergence of latent representations over training iterations for modified Barlow Twins model: decorrelated audio representations (left) and original small training data (right). The 128-dimensional latent space reveals the progression of learned features and their alignment throughout the training process.</figcaption>
</figure>

<hr />

<figure id="divergence_measures">
  <img src="http://yusufbrima.github.io/images/KL_Divergence.gif" style="width:45%;" alt="Kullback–Leibler divergence between two probability distributions.">
  <img src="http://yusufbrima.github.io/images/JSD_Divergence.gif" style="width:45%;"  alt="Jensen–Shannon divergence between two probability distributions.">
  <figcaption>A visual illustration of two divergence measure: the Kullback–Leibler (KL) and Jensen–Shannon (JS) divergences between two probability distributions $P_x $ and $Q_x$.</figcaption>
</figure>

<hr />

<figure id="Test_set_densenet121">
  <!-- <img src="http://yusufbrima.github.io/images/Test_set_densenet121.svg" style="width:45%;" alt="Explainable AI in Medical Image Analysis"> -->
  <img src="http://yusufbrima.github.io/images/BrainTumor_Saliency_Maps_inception_resnet_v2.png" style="width:100%;"  alt="Explainable AI in Medical Image Analysis">
  <figcaption>Explainable AI in Medical Image Analysis using Visual Saliency Maps. Feature attribution was done with a trained InceptionResNetv2 model.</figcaption>
</figure>

<hr />

<figure id="0">
  <img src="http://yusufbrima.github.io/images/0.png" style="width:45%;" alt="Workshop Poster Presentation">
  <img src="http://yusufbrima.github.io/images/1.gif" style="width:45%;" alt="Workshop Poster Presentation">
  <figcaption>Learnt 2D and 3D principal component latent representations of both human and non-human primates.</figcaption>
</figure>


<figure id="2">
  <img src="http://yusufbrima.github.io/images/2.png" style="width:45%;" alt="Workshop Poster Presentation">
  <img src="http://yusufbrima.github.io/images/3.gif" style="width:45%;" alt="Workshop Poster Presentation">
  <figcaption>Learnt 2D and 3D principal component latent representations of speeches at the United States Congress by five world leaders.</figcaption>
</figure>

# Recent News
* **February 19, 2025**; Talk on "Multimodal Federated Learning for Robust Lung Cancer Prognosis" at the [Fraunhofer Institute for Algorithms and Scientific Computing (SCAI)](https://www.slideshare.net/slideshow/multimodal-federated-learning-for-robust-lung-cancer-prognosis/276050973).
* **January 31, 2025**; Completed the MUST Deep Learning Bootcamp, North-West University, South Africa [MUST Deep Learning Bootcamp 2025](https://mailchi.mp/nithecs/must-bootcamp).
* **January 28, 2025**; "A Systematic Review of Low-Rank and Local Low-Rank Matrix Approximation in Big Data Medical Imaging" accepted for publication in [Neural Computing and Applications](https://arxiv.org/abs/2402.14045).
* **January 22, 2025**; PhD Dissertation Submitted and approved for examination and graduation: "Disentangled Representation Learning in Speech and Vocalization".
* **January 20, 2025**; The Association of Commonwealth Universities Case Study on "Advancing artificial intelligence for healthcare and developing human capital in low-resource settings" published in [ACU Research](https://www.acu.ac.uk/publications/case-studies/scholars-fellows-and-grantees-case-studies/advancing-artificial-intelligence-for-healthcare-and-developing-human-capital-in-low-resource-settings/).
* **January 11, 2025**; "Learning Disentangled Speech Representations" preprint published in [arXiv:2311.03389v4](https://arxiv.org/html/2311.03389v4).
* **December 16, 2024**; Talk on "Trustworthy Healthcare AI for Mental Health Risk Prediction" at the [Neurobiology Research Unit,Copenhagen University Hospital](https://www.slideshare.net/slideshow/trustworthy-healthcare-ai-for-mental-health-risk-prediction/275311658)
* **December 10, 2024**; Talk on "Assessing Explainability in Deep Learning for Medical Image Analysis" at the [Fraunhofer Institute for Algorithms and Scientific Computing (SCAI)](https://www.slideshare.net/slideshow/assessing-explainability-in-deep-learning-for-medical-image-analysis/275311589).
* **November 11, 2024**; Launched SyncSpeech Datasets: A large-scale collection of synthetic speech datasets for speech representation learning. Available at [SyncSpeech Datasets](https://synspeech.github.io/).
* **July 10, 2024**; Talk on "Assessing fusarium oxysporum disease severity in cotton using unmanned aerial system images and a hybrid domain adaptation deep learning time series model" at the [Leibniz Institute for Agricultural Engineering and Bioeconomy](https://www.slideshare.net/slideshow/assessing-fusarium-oxysporum-disease-severity-in-cotton-using-unmanned-aerial-system-images-and-a-hybrid-domain-adaptation-deep-learning-time-series-model/275313608)
* **June 22, 2024**; "Saliency-driven explainable deep learning in medical imaging: bridging visual explainability and statistical quantitative analysis" published in [BioData Mining 17, 18](https://doi.org/10.1186/s13040-024-00370-4).
* **March 27, 2024**; "Bridging the Gap: Exploring Interpretability in Deep Learning Models for Brain Tumor Detection and Diagnosis from MRI Images" published in [MDPI Information 2024, 15(4), 182](https://doi.org/10.3390/info15040182).  
* **March 21, 2024**; "Got accepted to attend in-person the [Deep Learning + Reinforcement Learning (DLRL) Summer School](https://dlrl.ca/) 2024 by CIFAR and the Vector Institute in Toronto, Canada.".
* **March 13, 2024**; Talk on "Causal Representation Learning" at the [Computer Vision Colloquium, Osnabrueck University](https://www.slideshare.net/slideshow/a-talk-on-deep-causal-representation-learning/270011604).
* **February 16, 2024**; "Learning Disentangled Audio Representations through Controlled Synthesis" accepted for oral presentation at [ICLR Tiny Papers 2024](https://iclr.cc/Conferences/2024/CallForTinyPapers/).
* **February 15, 2024**; "Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction" accepted for oral presentation at [MDPI Information 2024, 15(2), 114](https://doi.org/10.3390/info15020114).
* **February 12, 2024**; "Bridging the Gap: Exploring Interpretability in Deep Learning Models for Brain Tumor Classification from MRI Images" submitted to [MDPI Information Special Issue: Deep Learning in Medical Image Analysis: Foundations, Techniques, and Applications](https://www.mdpi.com/journal/information/special_issues/4VT8EQCTON).
* **December 10, 2023**; Attended [NeurIPS 2023](https://neurips.cc/Conferences/2023) in New Orleans, USA where Presented research poster on disentangled speech representation learning via self-supervision. Sharing novel techniques for learning interpretable and robust speech representations.
* **November 1, 2023**; "Learning Disentangled Speech Representations" accepted for poster presentation at [New in ML, NeurIPS 2023](https://newinml.github.io/).
* **October 17, 2023**; Co-organizing with [Ulf Krumnack](https://www.ikw.uni-osnabrueck.de/en/research_groups/computer_vision/people/krumnack_ulf.html) and Lukas Niehaus a [Seminar: Deep Representation Learning](https://studip.uni-osnabrueck.de/dispatch.php/course/details?sem_id=fc0b31d4ea24744a9e0bacb16c1f9987) (Winter 2023/24) at [Osnabrück University](https://www.comco.uni-osnabrueck.de/).
* **September 23, 2023**; "Self-Supervised Learning of Speech Representation via Redundancy Reduction" extended abstract published at [Gesellschaft für Informatik e.V.](https://doi.org/10.18420/ki2023-dc-02).
* **August 1, 2023**; "Visual Interpretable and Explainable Deep Learning Models for Brain Tumor MRI and COVID-19 Chest X-ray Images" published in [arXiv preprint arXiv:2208.00953](https://arxiv.org/abs/2208.00953).
* **July 26, 2023**; "Self-Supervised Learning of Speech Representation via Redundancy Reduction" accepted for oral presentation at [KI 2023 – 46th German Conference on Artificial Intelligence, Berlin, Germany](https://ki2023.gi.de/).
* **June 13, 2023**; submitted a manuscript to PLOS One [A Mathematical Framework for Understanding Recognition Systems](https://doi.org/10.1101/2023.06.08.544240).
* **September 16, 2022**; [Launched](https://www.eventbrite.de/e/welcome-to-the-graduate-assistance-initiative-network-gain-launching-tickets-409856942147) the [Graduate Assistance Initiative Network (GAIN)](https://gain.uos.de/) globally with 130+ attendees.
* **September 11-16, 2022**; Attended [Mediterranean Machine Learning school](https://www.m2lschool.org/past-editions/m2l-2022), Università Milano Bicocca, Milan, Italy.
* **August 6-7, 2022**; Co-organized with [Viktoria Zemliak](https://www.comco.uni-osnabrueck.de/projekte/viktoria_zemliak.html) the ["Bridging the Gap between Biological and Artificial Neural Networks" at the (Research Training Group (RTG) in Computational Cognition)](https://www.comco.uni-osnabrueck.de/workshop_2022.html).
* **July 29-August 6, 2022**; Attended and presented a poster at the [Bridging the technological gap – spreading technological innovations in the study of the human and non-human mind](https://www.primate-cognition.eu/de/veranstaltungen/bridging-the-technological-gap-workshop.html) at the German Primate Center in Göttingen, Germany.
* **July 11-29, 2022**; Participated in the [Neuromatch Academy: Deep Learning](https://academy.neuromatch.io/) intensive hands-on training.
* **August 16, 2021**; "Transfer Learning for the Detection and Diagnosis of Types of Pneumonia Including Pneumonia Induced by the COVID-19 from Chest X-Ray Images" published in [MDPI Special Issue on Machine Learning Applications for COVID-19 and Its Complications: Screening, Diagnosis, Treatment, and Prognosis](https://doi.org/10.3390/diagnostics11081480).
* **June 15, 2021**; Published a dataset that was curated in collaboration between the Computer Science and Engineering Department, University of Dhaka and the National Institute of Neuroscience, Bangladesh. It comprises 5,285 T1-weighted contrast-enhanced brain MRI images belonging to 38 categories. Available here [Brain MRI Dataset](https://doi.org/10.6084/m9.figshare.14778750.v2).
 <center>
 <iframe src="https://widgets.figshare.com/articles/14778750/embed?show_title=1" width="568" height="351" allowfullscreen frameborder="0"></iframe>
 </center>