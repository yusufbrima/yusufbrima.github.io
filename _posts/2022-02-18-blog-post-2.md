---
title: 'Understanding Sound from First Principles: Part 2'
date: 2022-02-18
permalink: /posts/2022/02/blog-post-2/
author: Yusuf Brima
tags:
  - Energry
  - Waves
  - Periodic Signal
  - Aperiodic Signal
  - Compression
  - Sound
  - Audio
  - Sampling
  - Quantization
---
<p class="page__date"><strong>
  <i class="fa fa-fw fa-user" aria-hidden="true"></i> Author:</strong>
  Yusuf Brima
</p>


<h2>Introduction</h2>
<p style="text-align:justify;">
We have made it thus far. For starters, please check out 
<a href='https://yusufbrima.github.io/posts/2022/02/blog-post-1/'>Part 1</a>, where delved into the underlying principles of sound creation from physical systems that vibrate. It laid the foundation for this and subsequent parts of the series as we walk our way through the layers of abstractions from signals to AI audio systems. 

Today, we are briefly going to talk about the broad classification of signals (i.e., speech, electric current, electric voltage, EGG recordings e.t.c.). There has been a grounds well of interest in studying the underlying principles of singals in a plethora of STEM (even social sciences are joining the bandwagon so to speak). The goal of this intellectual sprint is to gain a deeper appriciation of the potential applications of AI in sound research leveraging on the already mature body of work there exist in the space of signal processing. It can be quite tempting to follow the andrinaline rush of pursuing end-to-end learning from audio signals introduces phantom problems and less expressive (aka black-boxed models). As you may have realized, using a principled multi-scaled approach that leverages existing domain knowledge in signal processing helps tremendously in building AI models for speech signals. Enough with the motivational speech. Let's get technical!
<p>
<p style="text-align:justify;">

</p>


<!-- <h2>References</h2> -->
